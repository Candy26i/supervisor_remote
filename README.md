# ğŸ§  GRPO-PubMedQA Manual Training

This project fine-tunes a **Qwen-2.5-7B-Instruct** model on the **PubMedQA** dataset using a manually supervised **GRPO (Group Relative Policy Optimization)** pipeline.

---

## ğŸš€ How to Run

### ğŸ³ Option 1 â€” Using Docker (Recommended)

**Step 1:** Go into the project folder:
```bash
cd supervisor
```

**Step 2:** Build the Docker image:
```bash
docker build -t grpo-pubmedqa:latest .
```

**Step 3:** Run the container with GPU support:
```bash
docker run -it --gpus all -v ${PWD}:/workspace grpo-pubmedqa:latest
```

---

### ğŸ§© Option 2 â€” Run Locally (Without Docker)

**Step 1:** Install dependencies:
```bash
pip install -r requirements.txt
```

**Step 2:** Set up Weights & Biases (W&B) for experiment tracking:
```bash
export WANDB_API_KEY=your_key_here
export WANDB_PROJECT=GRPO-Qwen-PubMedQA-Manual
```

**Step 3:** Run the training script:
```bash
python main.py
```

---

## âœ… Notes

- Ensure you have a working **GPU + CUDA** setup.  
- **Weights & Biases** is optional but recommended for tracking metrics and losses.  
- You can modify the default model name or dataset path directly inside `main.py` if needed.  
- The model and tokenizer will be automatically downloaded from Hugging Face on first run.

---

## ğŸ§° Example Environment Variables (Windows PowerShell)
```powershell
setx WANDB_API_KEY "your_key_here"
setx WANDB_PROJECT "GRPO-Qwen-PubMedQA-Manual"
```

---

Thatâ€™s it! ğŸ¯  
Youâ€™re ready to train and evaluate your GRPO-based PubMedQA supervisor model.
